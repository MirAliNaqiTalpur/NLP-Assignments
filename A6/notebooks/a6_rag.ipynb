{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from langchain.document_loaders import PyMuPDFLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Source Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../data/linkedin_profile.pdf\n",
      "Loaded: ../data/personal_bio.txt\n",
      "Loaded: ../data/AIT_SIS_personal_info.txt\n",
      "Total documents loaded: 3\n",
      "Created 3 document chunks\n"
     ]
    }
   ],
   "source": [
    "# 1) Find all relevant sources about yourself\n",
    "\n",
    "# List your personal documents\n",
    "personal_docs = [\n",
    "    \"../data/linkedin_profile.pdf\",\n",
    "    \"../data/personal_bio.txt\",\n",
    "    \"../data/AIT_SIS_personal_info.txt\"\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "documents = []\n",
    "for doc_path in personal_docs:\n",
    "    try:\n",
    "        if doc_path.endswith('.pdf'):\n",
    "            loader = PyMuPDFLoader(doc_path)\n",
    "        elif doc_path.endswith('.txt'):\n",
    "            loader = TextLoader(doc_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {doc_path}\")\n",
    "            continue\n",
    "        docs = loader.load()\n",
    "        # Add source metadata to each document\n",
    "        for doc in docs:\n",
    "            doc.metadata[\"source\"] = os.path.basename(doc_path)\n",
    "        documents.extend(docs)\n",
    "        print(f\"Loaded: {doc_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {doc_path}: {e}\")\n",
    "\n",
    "print(f\"Total documents loaded: {len(documents)}\")\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=200\n",
    ")\n",
    "doc_chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(doc_chunks)} document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mir Ali\\AppData\\Local\\Temp\\ipykernel_25980\\1701810785.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Mir Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Vector store saved successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mir Ali\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "# Set up embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = FAISS.from_documents(doc_chunks, embedding_model)\n",
    "\n",
    "# Save vectorstore locally\n",
    "vectorstore.save_local(\"vectorstore\")\n",
    "print(\"Vector store saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful assistant that answers questions about Mir Ali Use the following context and chat history to provide a gentle and informative response. If the context doesn't provide the answer, politely say you don't have enough information.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Chat History: {chat_history}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"chat_history\", \"question\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "if not groq_api_key:\n",
    "    print(\"Error: GROQ_API_KEY environment variable not set.\")\n",
    "    exit()\n",
    "\n",
    "groq_llm = ChatGroq(\n",
    "    api_key=groq_api_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mir Ali\\AppData\\Local\\Temp\\ipykernel_25980\\2504715149.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "# Set up conversation memory\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    k=5,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=groq_llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mir Ali\\AppData\\Local\\Temp\\ipykernel_25980\\168687936.py:32: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain({\"question\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Model: FAISS with HuggingFace embeddings (sentence-transformers/all-MiniLM-L6-v2)\n",
      "Generator Model: Groq's llama-3.3-70b-versatile\n",
      "\n",
      "Analysis of Issues:\n",
      "- Retriever: FAISS may retrieve irrelevant chunks if embeddings fail to capture semantic meaning accurately. This could happen with ambiguous questions or insufficient document detail.\n",
      "- Generator: Groq's Llama3-70b might generate plausible but incorrect answers (hallucination) if retrieved context is incomplete.\n",
      "- Mitigation: Ensure documents are comprehensive, adjust chunk size/overlap, or refine the prompt to prioritize context adherence.\n",
      "\n",
      "Question 1: How old are you?\n",
      "Answer: To determine your age, I'll need to calculate the difference between the current year and your birth year. Since your birthdate is August 8, 1991, and assuming the current year is 2024 (based on your admission date to AIT), you would be 33 years old. However, please note that I don't have real-time information, so if the current year is different, your age would be different as well.\n",
      "\n",
      "Question 2: What is your highest level of education?\n",
      "Answer: Based on the provided context, your current highest level of education is a Bachelor's degree in City and Regional Planning, which you completed at Mehran University of Engineering and Technology in 2015. However, you are currently pursuing a Master's degree in Data Science and Artificial Intelligence at the Asian Institute of Technology, which you started in August 2024 and are expected to complete in June 2026.\n",
      "\n",
      "Question 3: What major or field of study did you pursue during your education?\n",
      "Answer: Based on the provided context, during your undergraduate studies at Mehran University of Engineering and Technology, you pursued a major in City and Regional Planning. You completed your Bachelor's degree in this field in 2015. Currently, you are pursuing a Master's degree in Data Science and Artificial Intelligence at the Asian Institute of Technology.\n",
      "\n",
      "Question 4: How many years of work experience do you have?\n",
      "Answer: Based on the provided context, it appears that you have at least 2 years and 8 months of work experience as a Lab Supervisor at Mehran University of Engineering and Technology, from March 2016 to October 2018. However, I don't have enough information to determine if you have acquired any additional work experience beyond this period.\n",
      "\n",
      "Question 5: What type of work or industry have you been involved in?\n",
      "Answer: Based on the provided context, it appears that you have been involved in the field of education, specifically in a laboratory setting, as a Lab Supervisor at Mehran University of Engineering and Technology. Additionally, your educational background in City and Regional Planning, as well as your current pursuit of a Master's degree in Data Science and Artificial Intelligence, suggests that you may also have an interest in or experience with urban planning, geographic information systems (GIS), and data analytics. However, I don't have enough information to determine if you have worked in any other industries or types of work beyond your experience as a Lab Supervisor.\n",
      "\n",
      "Question 6: Can you describe your current role or job responsibilities?\n",
      "Answer: Based on the provided context, I don't have enough information to determine your current job responsibilities or role. The context only mentions your experience as a Lab Supervisor at Mehran University of Engineering and Technology from March 2016 to October 2018, but it does not provide information about your current job or role. Additionally, it mentions that you are currently pursuing a Master's degree in Data Science and Artificial Intelligence at the Asian Institute of Technology, but it does not specify if you are working while studying or what your current job responsibilities might be.\n",
      "\n",
      "Question 7: What are your core beliefs regarding the role of technology in shaping society?\n",
      "Answer: Based on the provided context, I don't have enough information to determine your core beliefs regarding the role of technology in shaping society. The context provides information about your educational background, work experience, and skills, but it does not explicitly state your beliefs or opinions on the role of technology in society.\n",
      "\n",
      "However, it can be inferred that you have an interest in technology, as evidenced by your pursuit of a Master's degree in Data Science and Artificial Intelligence, as well as your certifications in areas such as Google IT Support, Advanced Data Analytics, and AWS Cloud Solutions Architecture. Additionally, your experience as a Lab Supervisor and your skills in areas such as Project Management, Urban Planning, and Geographic Information Systems (GIS) suggest that you may have a practical understanding of how technology can be applied to real-world problems.\n",
      "\n",
      "If you'd like to share your thoughts on the role of technology in shaping society, I'd be happy to engage in a discussion with you.\n",
      "\n",
      "Question 8: How do you think cultural values should influence technological advancements?\n",
      "Answer: Based on the provided context, I don't have enough information to determine your specific thoughts on the role of cultural values in shaping the development and implementation of new technologies. The context provides information about your educational background, work experience, and skills, but it does not explicitly state your opinions or beliefs on this topic.\n",
      "\n",
      "However, as someone who is pursuing a Master's degree in Data Science and Artificial Intelligence and has a background in City and Regional Planning, you may have an appreciation for the importance of considering cultural values in the development and implementation of new technologies. Your experience working in a laboratory setting and your skills in areas such as Project Management, Urban Planning, and Geographic Information Systems (GIS) may also suggest that you understand the importance of considering the social and cultural context in which technologies are developed and implemented.\n",
      "\n",
      "In general, cultural values can play a significant role in shaping the development and implementation of new technologies, as they can influence the way technologies are designed, used, and perceived by different communities. Considering cultural values can help ensure that technologies are developed and implemented in a way that is respectful, inclusive, and beneficial to diverse groups of people.\n",
      "\n",
      "If you'd like to share your thoughts on the role of cultural values in shaping the development and implementation of new technologies, I'd be happy to engage in a discussion with you.\n",
      "\n",
      "Question 9: As a master's student, what is the most challenging aspect of your studies so far?\n",
      "Answer: Based on the provided context, I don't have enough information to determine the most challenging aspect of pursuing a Master's degree in Data Science and Artificial Intelligence from your personal perspective. The context provides information about your educational background, work experience, and skills, but it does not explicitly state your thoughts or opinions on the challenges you are facing in your current program.\n",
      "\n",
      "However, pursuing a Master's degree in Data Science and Artificial Intelligence can be challenging in general, as it requires a strong foundation in mathematical and computational concepts, as well as the ability to analyze and interpret complex data sets. Some common challenges that students in this field may face include staying up-to-date with the latest developments and advancements in the field, balancing the theoretical and practical aspects of the program, and applying data science and artificial intelligence concepts to real-world problems.\n",
      "\n",
      "If you'd like to share your thoughts on the challenges you are facing in your program, I'd be happy to engage in a discussion with you and provide any guidance or support that I can.\n",
      "\n",
      "Question 10: What specific research interests or academic goals do you hope to achieve during your time as a master's student?\n",
      "Answer: Based on the provided context, I don't have enough information to determine your specific research interests or academic goals as a master's student in Data Science and Artificial Intelligence. The context provides information about your educational background, work experience, and skills, but it does not explicitly state your research interests or academic goals.\n",
      "\n",
      "However, given your background in City and Regional Planning and your current pursuit of a Master's degree in Data Science and Artificial Intelligence, you may be interested in exploring research topics that combine urban planning, geographic information systems (GIS), and data analytics. Some potential research areas could include using data science and artificial intelligence to analyze and optimize urban planning decisions, develop more efficient transportation systems, or create more sustainable and resilient cities.\n",
      "\n",
      "If you'd like to share your research interests or academic goals, I'd be happy to engage in a discussion with you and provide any guidance or support that I can.\n",
      "\n",
      "Answers saved to 'answers.json'\n"
     ]
    }
   ],
   "source": [
    "# List retriever and generator models\n",
    "print(\"Retriever Model: FAISS with HuggingFace embeddings (sentence-transformers/all-MiniLM-L6-v2)\")\n",
    "print(\"Generator Model: Groq's llama-3.3-70b-versatile\")\n",
    "\n",
    "# 5) Analyze potential issues\n",
    "print(\"\"\"\n",
    "Analysis of Issues:\n",
    "- Retriever: FAISS may retrieve irrelevant chunks if embeddings fail to capture semantic meaning accurately. This could happen with ambiguous questions or insufficient document detail.\n",
    "- Generator: Groq's Llama3-70b might generate plausible but incorrect answers (hallucination) if retrieved context is incomplete.\n",
    "- Mitigation: Ensure documents are comprehensive, adjust chunk size/overlap, or refine the prompt to prioritize context adherence.\n",
    "\"\"\")\n",
    "\n",
    "# Task 3: Chatbot Development\n",
    "\n",
    "# Define the 10 required questions\n",
    "questions = [\n",
    "    \"How old are you?\",\n",
    "    \"What is your highest level of education?\",\n",
    "    \"What major or field of study did you pursue during your education?\",\n",
    "    \"How many years of work experience do you have?\",\n",
    "    \"What type of work or industry have you been involved in?\",\n",
    "    \"Can you describe your current role or job responsibilities?\",\n",
    "    \"What are your core beliefs regarding the role of technology in shaping society?\",\n",
    "    \"How do you think cultural values should influence technological advancements?\",\n",
    "    \"As a master's student, what is the most challenging aspect of your studies so far?\",\n",
    "    \"What specific research interests or academic goals do you hope to achieve during your time as a master's student?\"\n",
    "]\n",
    "\n",
    "# Generate answers and store in JSON format\n",
    "results = []\n",
    "for i, question in enumerate(questions, start=1):\n",
    "    response = qa_chain({\"question\": question})\n",
    "    answer = response[\"answer\"]\n",
    "    results.append({\n",
    "        \"question_number\": i,\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "    # Print the question number, question, and answer\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(\"answers.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Answers saved to 'answers.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
